# -*- coding: utf-8 -*-
"""model_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZKufhQIOVZH0aI46YByv7LRIqYOznqJU
"""

import pandas as pd
import numpy as np
from google.colab import files


uploaded = files.upload()
uploaded

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import seaborn as sns
import matplotlib.pyplot as plt

# Load your cleaned dataset
df = pd.read_csv("merged_big5_scores.csv")

# Select trait columns
traits = df[["Openness", "Conscientiousness", "Extraversion", "Agreeableness", "Neuroticism"]]

# Standardize features
scaler = StandardScaler()
traits_scaled = scaler.fit_transform(traits)

# Apply KMeans clustering
kmeans = KMeans(n_clusters=4, random_state=42)
df["Cluster"] = kmeans.fit_predict(traits_scaled)

# Analyze each cluster
cluster_summary = df.groupby("Cluster")[["Openness", "Conscientiousness", "Extraversion", "Agreeableness", "Neuroticism"]].mean()
print(cluster_summary)

# Optional: visualize with seaborn
sns.pairplot(df, vars=traits.columns, hue="Cluster", palette="Set2")
plt.suptitle("Personality Trait Clusters", y=1.02)
plt.show()

# Function to map clusters to career roles
def assign_career(cluster):
    if cluster == 0:
        return "Data Analyst, Business Analyst, Project Manager"
    elif cluster == 1:
        return "Software Developer, Technical Specialist, Engineer"
    elif cluster == 2:
        return "Artist, Researcher, Freelancer, Startup Roles"
    elif cluster == 3:
        return "HR, Product Manager, Customer Success, Teaching"
    else:
        return "Unknown"

# Assuming the 'Cluster' column contains the cluster IDs for each individual
df['Career Role'] = df['Cluster'].apply(assign_career)

# Save the updated CSV file
df.to_csv('updated_data.csv', index=False)

print("Career roles added to the CSV file!")
df

import pandas as pd

# Load the CSV data (replace this with the actual file path if it's locally stored)
df = pd.read_csv('updated_data.csv')  # Update with the actual file path

# Display the first few rows to check the data
print(df.head())

from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
label_encoder = LabelEncoder()

# Encode the 'Career Role' column
df['Career Role'] = label_encoder.fit_transform(df['Career Role'])

# Display the updated DataFrame to check
print(df.head())



# Extracting the features (personality traits)
X = df[['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']]

# The target column
y = df['Career Role']

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Initialize the Random Forest Classifier
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")

from sklearn.metrics import classification_report

# Print classification report for more metrics
print(classification_report(y_test, y_pred))

#SVM

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# X = your personality trait features
# y = your cluster labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

svm_model = SVC(kernel='rbf')  # or 'linear'
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)
print(classification_report(y_test, y_pred))

#KNN

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Assuming X = trait features, y = cluster labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

knn = KNeighborsClassifier(n_neighbors=5)  # You can tune 'k'
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
report = classification_report(y_test, y_pred, output_dict=True)

# Print results in %
for label in ['0', '1', '2', '3']:
    print(f"\nCluster {label}:")
    print(f"Precision: {round(report[label]['precision']*100, 1)}%")
    print(f"Recall: {round(report[label]['recall']*100, 1)}%")
    print(f"F1-Score: {round(report[label]['f1-score']*100, 1)}%")

import joblib


# Save the trained model
joblib.dump(model, 'career_prediction_model.pkl')


# Load the saved model (replace 'career_prediction_model.pkl' with your actual model file)
model = joblib.load('career_prediction_model.pkl')

# New individual personality traits
new_data = {
    'Openness': [3.0],  # Example value for Openness
    'Conscientiousness': [2.5],  # Example value for Conscientiousness
    'Extraversion': [2.8],  # Example value for Extraversion
    'Agreeableness': [3.2],  # Example value for Agreeableness
    'Neuroticism': [2.0]  # Example value for Neuroticism
}

# Convert the new data into a DataFrame
import pandas as pd
new_df = pd.DataFrame(new_data)

# Use the trained model to predict the career role (using the same features)
predicted_class = model.predict(new_df)

# Map the predicted class back to the original career role labels
career_roles = ['Data Analyst, Business Analyst, Project Manager',
                'Artist, Researcher, Freelancer, Startup Roles',
                'Artist, Researcher, Freelancer, Startup Roles',
                'HR, Product Manager, Customer Success, Teaching']  # Example career roles based on your data

# Output the predicted career role
predicted_career_role = career_roles[predicted_class[0]]  # Get the corresponding career role
print(f"The predicted career role is: {predicted_career_role}")

import speech_recognition as sr
import moviepy.editor as mp
import pandas as pd
from deepface import DeepFace
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
import joblib

# Load the saved model for career prediction
model = joblib.load('career_prediction_model.pkl')

# Example function to extract speech from the video
def extract_audio_from_video(video_path):
    video = mp.VideoFileClip(video_path)
    audio = video.audio
    audio_path = "extracted_audio.wav"
    audio.write_audiofile(audio_path)
    return audio_path

# Function to convert speech to text
def speech_to_text(audio_path):
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio = recognizer.record(source)
    return recognizer.recognize_google(audio)

# Extract personality traits using NLP (this could be advanced in a real setup)
def extract_personality_features_from_text(text):
    # Placeholder: You'd replace this with a model that maps text to Big 5 personality traits
    # For now, it returns dummy values based on text sentiment
    return {
        'Openness': 3.0,
        'Conscientiousness': 2.5,
        'Extraversion': 3.0,
        'Agreeableness': 2.8,
        'Neuroticism': 2.0
    }

# Example function to detect facial expressions (could correlate with traits like Agreeableness)
def extract_face_features_from_video(video_path):
    # Use DeepFace or any emotion detection model to extract emotions
    analysis = DeepFace.analyze(video_path, actions=['emotion'], enforce_detection=False)
    return analysis[0]['dominant_emotion']

# Main function to predict career role from video
def predict_career_from_video(video_url):
    # Extract the audio from the video
    audio_path = extract_audio_from_video(video_url)

    # Convert the audio to text
    text = speech_to_text(audio_path)

    # Extract personality features from the text
    personality_features = extract_personality_features_from_text(text)

    # Optionally, extract facial features or emotions from the video itself
    dominant_emotion = extract_face_features_from_video(video_url)

    # Combine all features (you may want to process this data further)
    features = pd.DataFrame([personality_features])

    # Predict the career role using the trained model
    predicted_class = model.predict(features)

    # Map the predicted class to career roles (same as before)
    career_roles = ['Data Analyst, Business Analyst, Project Manager',
                    'Artist, Researcher, Freelancer, Startup Roles',
                    'Artist, Researcher, Freelancer, Startup Roles',
                    'HR, Product Manager, Customer Success, Teaching']

    predicted_career_role = career_roles[predicted_class[0]]
    return predicted_career_role

# Example usage
video_url = ""  # Replace this with the actual URL or path
predicted_role = predict_career_from_video(video_url)
print(f"The predicted career role is: {predicted_role}")

!pip install SpeechRecognition moviepy deepface

import pandas as pd
import numpy as np
from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import classification_report
import joblib

# For Jupyter widget upload
import ipywidgets as widgets
from IPython.display import display

# --- Step 1: Load and preprocess CSV ---

df = pd.read_csv('updated_data.csv')

# Clean and preprocess Career Role column
df = df.dropna(subset=['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism', 'Career Role'])
df['Career Role'] = df['Career Role'].astype(str).apply(lambda x: [role.strip() for role in x.split(',')])

# Features and target
features = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']
X = df[features].values

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Multi-label binarize target
mlb = MultiLabelBinarizer()
y = mlb.fit_transform(df['Career Role'])

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# --- Step 2: Train multi-label classifier ---

base_clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf = MultiOutputClassifier(base_clf)
clf.fit(X_train, y_train)

# Evaluate
y_pred = clf.predict(X_test)
print("Classification report:\n")
print(classification_report(y_test, y_pred, target_names=mlb.classes_))

# Save model and encoders for reuse
joblib.dump(clf, 'career_big5_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(mlb, 'mlb.pkl')

# --- Step 3: Prediction function ---

def predict_career(openness, conscientiousness, extraversion, agreeableness, neuroticism):
    traits = np.array([[openness, conscientiousness, extraversion, agreeableness, neuroticism]])
    traits_scaled = scaler.transform(traits)
    pred = clf.predict(traits_scaled)
    careers = mlb.inverse_transform(pred)
    return careers[0] if careers else []

# --- Step 4: Placeholder for Big Five trait extraction from video ---

def extract_big5_traits_from_video(video_path):
    """
    Replace this function with your actual video processing pipeline.
    Currently returns random traits for demonstration.
    """
    print(f"Processing video for trait extraction: {video_path}")
    return np.random.uniform(2, 4, size=5)

# --- Step 5: Jupyter widget for video upload and prediction ---

uploader = widgets.FileUpload(
    accept='.mp4, .avi, .mov',
    multiple=False,
    description='Upload Video'
)
display(uploader)

def on_upload_change(change):
    if uploader.value:
        for filename, file_info in uploader.value.items():
            # Save uploaded video locally
            with open(filename, 'wb') as f:
                f.write(file_info['content'])
            print(f"Saved uploaded video as {filename}")

            # Extract Big Five traits from the video (placeholder)
            traits = extract_big5_traits_from_video(filename)
            print(f"Extracted Big Five traits: {traits}")

            # Predict career roles
            predicted_roles = predict_career(*traits)
            print(f"Predicted career roles: {predicted_roles}")

uploader.observe(on_upload_change, names='value')

# --- Step 6: Example usage without video ---

if __name__ == "__main__":
    example_traits = [3.5, 4.0, 3.2, 4.1, 2.5]
    predicted = predict_career(*example_traits)
    print(f"Example prediction for traits {example_traits}: {predicted}")